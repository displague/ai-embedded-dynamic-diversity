# Experiment Log

Use compact entries:
- date:
- hypothesis:
- change:
- result:
- next action:

- date: 2026-02-13
- hypothesis: Embodiment-aware remap schedules plus explicit environment controls will make adaptation behavior easier to observe and compare.
- change: Added world environment controls (wind/light/force/object move), embodiment schemas, and single+comparison visualizer commands; added curriculum schedules and latent genetic memory in training.
- result: Smoke training and visualization completed; generated `artifacts/adaptation-controlled.gif` and `artifacts/adaptation-compare-controlled.gif` with remap events and adaptation traces.
- next action: Run longer RTX 5080 training and compare checkpoints across all three embodiments.
- date: 2026-02-13
- hypothesis: Longer parallel co-evolution with optional gating flags plus curriculum/genetic-memory toggles should produce a clearer best-performing variant and better run-to-run comparability.
- change: Added principle tests (`tests/test_principles.py`) and ran `add-train-parallel` equivalent with 8 variants, 30 epochs, mixed optional flags into `artifacts/parallel-long`.
- result: All 8 variants completed successfully and produced checkpoints, logs, and metrics summary (`artifacts/parallel-long/summary.json`). Primitive principle tests passed (5/5).
- next action: Rank top variants by fitness and generate side-by-side visualization comparisons for best 2-3 models across `hexapod/car/drone`.
- date: 2026-02-13
- hypothesis: Direct cross-embodiment ranking across shared scenario schedules will expose transfer-generalization differences better than single-fitness ranking.
- change: Added `add-cross-eval` (`src/ai_embedded_dynamic_diversity/train/cross_eval_cli.py`) and transfer tests (`tests/test_cross_eval.py`), then evaluated `artifacts/parallel-long`.
- result: `artifacts/cross-eval-summary.json` ranked `artifacts/parallel-long/variant-03.pt` highest by overall transfer score (~0.2961) across `hexapod/car/drone` under `mild/gust/force` scenarios.
- next action: Generate side-by-side visual comparisons for top-ranked checkpoints (`variant-03` vs `variant-02`) across each embodiment and inspect failure modes where mismatch spikes after remaps.
- date: 2026-02-13
- hypothesis: Top transfer-ranked checkpoints should show more consistent vitality under remaps across all embodiments.
- change: Generated side-by-side visual comparisons for top ranked models (`variant-03` vs `variant-02`) across `hexapod`, `car`, and `drone`.
- result: Produced `artifacts/cross-eval-top-hexapod.gif`, `artifacts/cross-eval-top-car.gif`, and `artifacts/cross-eval-top-drone.gif`; left model (`variant-03`) showed slightly higher final vitality in all three.
- next action: Build automated delta charts (mismatch/vitality) from `cross-eval-summary.json` and inspect per-remap recovery dips.
- date: 2026-02-13
- hypothesis: A focused long retrain on the best-transfer configuration should improve cross-embodiment transfer score beyond the current top checkpoint.
- change: Added `add-cross-report`, extended `add-cross-eval` with `--checkpoints-list`, trained `artifacts/focused-variant03-long.pt` (symplectic + topk + dmd + phase + coevolution + genetic memory), and evaluated against `variant-03` and `variant-02`.
- result: Focused model ranked #1 in `artifacts/cross-eval-focused-vs-top.json` with transfer score ~0.32448 (vs ~0.29614 and ~0.29556). Generated comparison report/csv and visualization `artifacts/focused-vs-old-top-hexapod.gif`.
- next action: Re-run focused training with curriculum enabled and compare whether robustness gains persist across harsher scenario mixes.
- date: 2026-02-13
- hypothesis: Curriculum-enabled focused training should improve transfer under hardy disturbance profiles.
- change: Added hardy/standard/extreme scenario profiles to `add-cross-eval`; generated focused-vs-old visualizations for `car` and `drone`; trained `artifacts/focused-variant03-curriculum.pt`; evaluated against focused and prior top checkpoints under hardy profile.
- result: Hardy ranking in `artifacts/cross-eval-hardy-focused-vs-top.json` kept `artifacts/focused-variant03-long.pt` #1 (~0.30826), curriculum model #2 (~0.30619), both above prior parallel tops (~0.281). Generated `artifacts/focused-vs-old-top-car.gif`, `artifacts/focused-vs-old-top-drone.gif`, and `artifacts/focused-curriculum-vs-focused-long-drone-hardy.gif`.
- next action: Tune curriculum schedules (start/end remap volatility) and re-test on hardy profile to close the remaining gap.
- date: 2026-02-13
- hypothesis: Curriculum schedule tuning may surpass the current focused non-curriculum champion on hardy-line transfer.
- change: Trained `focused-curriculum-a` and `focused-curriculum-b` variants, then evaluated a hardy sweep in `artifacts/cross-eval-hardy-curriculum-sweep.json`; generated comparison visualization `artifacts/focused-currA-vs-focused-long-car-hardy.gif`.
- result: Ranking stayed led by `artifacts/focused-variant03-long.pt` (~0.30826). Curriculum variants reached ~0.30619 (`focused-variant03-curriculum`), ~0.30564 (`focused-curriculum-a`), and ~0.29824 (`focused-curriculum-b`). All focused variants outperformed prior `parallel-long/variant-03` (~0.28134).
- next action: Target car-specific robustness (crosswind/force) and consider embodiment-aware objective weighting in transfer score.
- date: 2026-02-17
- hypothesis: Embodiment-weighted ranking (`car` priority) may change hardy-line checkpoint selection and better reflect near-term deployment priorities.
- change: Added `--embodiment-weights` support to `add-cross-eval`, added parser/weighting tests, ran weighted hardy evaluation in `artifacts/cross-eval-hardy-car-priority.json` with `hexapod=1,car=2.5,drone=1`, and generated report outputs (`.md`, `.csv`).
- result: Top checkpoint did not change; `artifacts/focused-variant03-long.pt` remained #1 (`weighted ~0.29343`, `unweighted ~0.31016`). Car transfer remained the limiting factor despite weighted selection.
- next action: Add car-focused objective weighting/sampling during training (storm/crosswind emphasis), then rerun hardy weighted+unweighted comparisons.
- date: 2026-02-17
- hypothesis: Explicit embodiment-mismatch optimization during training (including new high-DOF stress embodiment) should improve transferable adaptation, especially car mismatch under hardy stressors.
- change: Added `polymorph120` embodiment, added embodiment-aware transfer loss/fitness terms and warm-start support to training (`--embodiments`, `--enable-embodiment-transfer-loss`, `--transfer-loss-weight`, `--transfer-fitness-weight`, `--transfer-samples-per-step`, `--init-weights`), and ran:
  - aggressive scratch sweep: `artifacts/parallel-aggressive-cpu`
  - warm-start fine-tune from champion: `artifacts/focused-variant03-long-poly-ft.pt`
- result: Scratch aggressive variants did not beat champion on legacy hardy score. Warm-start fine-tune did beat champion:
  - `artifacts/cross-eval-focused-vs-polyft-hardy.json`: `0.32899` vs `0.30826`
  - `artifacts/cross-eval-focused-vs-polyft-standard.json`: `0.34748` vs `0.32448`
  - `artifacts/cross-eval-focused-vs-polyft-hardy-car-priority.json`: weighted score `0.31125` vs `0.28209`
  - car mismatch improved from `1.48385` to `1.25366`
  - 4-emb hardy score (with `polymorph120`) also improved (`0.36389` vs `0.34795`)
- next action: Run car-priority weighted hardy eval including `polymorph120` and tune transfer-fitness weight so proxy fitness aligns better with transfer improvements.
- date: 2026-02-17
- hypothesis: Moving the warm-start + transfer-objective pipeline to CUDA and running a mixed device sweep should reduce mismatch further while improving hardy transfer.
- change: Installed CUDA PyTorch (`2.10.0+cu128`) in `.venv`, trained `artifacts/focused-variant03-long-poly-ft-cuda.pt`, then ran mixed-device warm-start sweep `artifacts/parallel-cuda-mixed-sweep` and evaluated top checkpoints with `runs_per_combo=2`.
- result: `artifacts/parallel-cuda-mixed-sweep/variant-01.pt` became new best across standard/hardy/car-priority/poly4:
  - standard: `0.38302` (prev `0.37217`)
  - hardy: `0.36079` (prev `0.35110`)
  - hardy car-priority: `0.34523` (prev `0.33477`)
  - hardy car mismatch: `0.95847` (prev `1.04158`)
  - hardy poly4: `0.38828` (prev `0.38086`)
  - comparison viz: `artifacts/polyft-cuda-vs-v01-car-hardy.gif`
- next action: Lock reproducible CUDA dependency workflow for `uv`, then run a longer RTX-only sweep using `variant-01` as warm-start with stronger storm/crosswind weighting.
- date: 2026-02-17
- hypothesis: A longer CUDA-heavy warm-start sweep with stronger transfer pressure (`transfer_loss_weight=0.5`, `transfer_fitness_weight=0.16`, `samples=4`) can reduce hardy mismatch and especially car mismatch below `0.9`.
- change: Ran `artifacts/parallel-cuda-long-v02` (`8` variants, `48` epochs, warm-start from `artifacts/parallel-cuda-mixed-sweep/variant-01.pt`), then strict cross-evals (`runs_per_combo=2`) on hardy, hardy car-priority, and hardy poly4. Added strict device guard (`--strict-device`) to training CLIs with tests.
- result: `artifacts/parallel-cuda-long-v02/variant-01.pt` became new best across all hardy evaluations:
  - standard: `0.41071` vs old champion `0.37877`
  - hardy: `0.38989` vs old champion `0.36234`
  - hardy car-priority: `0.37822` vs `0.34798`
  - hardy poly4: `0.41016` vs `0.38907`
  - hardy overall mismatch: `0.54666` vs `0.67971`
  - hardy car mismatch: `0.71312` vs `0.91944` (crossed target `<0.9`)
  - comparison viz: `artifacts/cuda-long-v02-v01-car-crosswind.gif` (`final_mismatch 0.556` vs `0.633`)
- next action: Push car hardy mismatch below `0.70` with lower variance across repetitions and standardize CUDA lock/index handling in `uv` so plain `uv run` remains GPU-backed.
- date: 2026-02-17
- hypothesis: A longer convergence-focused warm-start sweep plus higher-repeat ranking (`runs_per_combo=4..6`) should improve hardy transfer while confirming stability beyond short-run noise.
- change: Reinstalled CUDA torch in `.venv` (`cu130`), ran `artifacts/parallel-cuda-converge-v03` (10 variants, 56 epochs, warm-start from `artifacts/model-core-champion-v02.pt`), then evaluated top candidates with high-repeat validations:
  - `artifacts/cross-eval-cuda-converge-v03-top5-hardy-r4.json`
  - `artifacts/cross-eval-cuda-converge-v03-top5-hardy-car-priority-r4.json`
  - `artifacts/cross-eval-cuda-converge-v03-top5-standard-r3.json`
  - `artifacts/cross-eval-cuda-converge-v03-top5-hardy-poly4-r3.json`
  - `artifacts/cross-eval-cuda-converge-v03-top4-hardy-r6.json`
  - `artifacts/cross-eval-cuda-converge-v03-top4-hardy-car-priority-r6.json`
- result: `artifacts/parallel-cuda-converge-v03/variant-07.pt` stayed #1 across all profiles/repeat levels and was promoted to `artifacts/model-core-champion-v03.pt`:
  - hardy r6: `0.41967` vs champion-v02 `0.39073`
  - hardy car-priority r6: `0.41226` vs `0.37992`
  - standard r3: `0.45133` vs `0.41668`
  - hardy car mismatch (r6): `0.50892` vs `0.68657`
  - comparison viz: `artifacts/converge-v03-v07-vs-v02-car-crosswind.gif`
- next action: Target `<0.50` hardy car mismatch and reduce car transfer variance under `storm/crosswind` without regressing standard transfer.
